{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1><font size=\"+3.5\" color=\"blue\" style=\"font-family: Futura\"><center>Natural Langauge Processing</center></font></h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3' style=\"font-family: Futura\">In current genreation NLP is going heigher and higher everyday. So many bigtech companies are using NLP im there product. like <a href=\"https://google.com\">Google</a> in Google assistant, <a href=\"https://apple.com\">Apple</a> in siri, <a href=\"https:www.amazon.com\">Amazon</a> in Alexa, <a href='https://microsoft.com'>Microsoft</a> and so on.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3' style=\"font-family: Futura\">Here I am going to explain Natural Langauge Processing. I have learn lot of thing from good Youtube channels and so many blogs which i sharing here which will help you also. <a href=\"https://www.youtube.com/playlist?list=PLZoTAELRMXVMdJ5sqbCK2LiM0HhQVWNzm\">NLP Basic(Youtube)</a> and <a href=\"https://towardsdatascience.com/your-guide-to-natural-language-processing-nlp-48ea2511f6e1\">Blog</a> this site and channle both helping me so much to learn Data Science and Machine learnig. Here i am using some diffrent approch for presentation which i learn from this <a href='https://www.kaggle.com/vishalvanpariya/house-pricing-ultimate-guide/edit'>kernel</a>.</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-family: Futura; color:blue;\">Overview</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* [<font size='3' style=\"font-family: Futura\">1.Importing Important Libraries</font>](#1)\n",
    "* [<font size='3' style=\"font-family: Futura\">2.Importing Data</font>](#2)\n",
    "* [<font size='3' style=\"font-family: Futura\">3.Data Cleaning</font>](#3)\n",
    "* [<font size='3' style=\"font-family: Futura\">4.Feature Scalling</font>](#4)\n",
    "* [<font size='3' style=\"font-family: Futura\">5.Modeling</font>](#5)\n",
    "* [<font size='3' style=\"font-family: Futura\">6.Submission</font>](#6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-family: Futura; color:green \"><b>1. Libraries</b></h2><br><a id='1'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "from nltk import word_tokenize\n",
    "from collections import defaultdict\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import string\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3' style=\"font-family: Futura\">\n",
    "<b style=\"color:blue\">Use Of Liberaries:</b><br><br>\n",
    "    &emsp;&emsp;<b style=\"color:green\">1. Numpy :</b> we will use it for maths opration<br>\n",
    "    &emsp;&emsp;<b style=\"color:green\">2. Pandas :</b> Data Handling<br>\n",
    "    &emsp;&emsp;<b style=\"color:green\">3. re :</b> Regular Expression<br>\n",
    "    &emsp;&emsp;<b style=\"color:green\">4. Stopwords :</b> Remove Stopwords<br>\n",
    "    &emsp;&emsp;<b style=\"color:green\">5. PorterStemmer :</b> For Stemming<br>\n",
    "    &emsp;&emsp;<b style=\"color:green\">6. word_tokenize :</b> For work token<br>\n",
    "    &emsp;&emsp;<b style=\"color:green\">7. defaultdict :</b> For dictionary<br>\n",
    "    &emsp;&emsp;<b style=\"color:green\">8. WordNetLemmatizer :</b> For word lemmatize<br>\n",
    "    &emsp;&emsp;<b style=\"color:green\">9. String :</b> For string oprations<br>\n",
    "    &emsp;&emsp;<b style=\"color:green\">10. TfidfVectorizer :</b> Vecterization<br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-family: Futura; color:green \"><b>2. Import Data</b></h2><br><a id='2'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=pd.read_csv('train.csv')\n",
    "test=pd.read_csv('test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-family: Futura; color:green \"><b>3. Data Cleaning</b></h2><br><a id='3'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>keyword</th>\n",
       "      <th>location</th>\n",
       "      <th>text</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Our Deeds are the Reason of this #earthquake M...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Forest fire near La Ronge Sask. Canada</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>All residents asked to 'shelter in place' are ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>13,000 people receive #wildfires evacuation or...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Just got sent this photo from Ruby #Alaska as ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id keyword location                                               text  \\\n",
       "0   1     NaN      NaN  Our Deeds are the Reason of this #earthquake M...   \n",
       "1   4     NaN      NaN             Forest fire near La Ronge Sask. Canada   \n",
       "2   5     NaN      NaN  All residents asked to 'shelter in place' are ...   \n",
       "3   6     NaN      NaN  13,000 people receive #wildfires evacuation or...   \n",
       "4   7     NaN      NaN  Just got sent this photo from Ruby #Alaska as ...   \n",
       "\n",
       "   target  \n",
       "0       1  \n",
       "1       1  \n",
       "2       1  \n",
       "3       1  \n",
       "4       1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3' style=\"font-family: Futura\">\n",
    "<b style=\"color:green\">id</b> - a unique identifier for each tweet<br>\n",
    "    <b style=\"color:green\">text</b> - the text of the tweet<br>\n",
    "<b style=\"color:green\">location</b> - the location the tweet was sent from (may be blank)<br>\n",
    "<b style=\"color:green\">keyword</b> - a particular keyword from the tweet (may be blank)<br>\n",
    "<b style=\"color:green\">target</b> - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)<br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3' style=\"font-family: Futura\">Let's delete keyword and location</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train=train.drop('keyword',1)\n",
    "train=train.drop('location',1)\n",
    "\n",
    "test=test.drop('keyword',1)\n",
    "test=test.drop('location',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3' style=\"font-family: Futura\">let's have important data from Dataframe</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train=train.iloc[:,-1]\n",
    "x_train=train.iloc[:,:-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps=PorterStemmer()\n",
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataclean(data):\n",
    "    corpus=[]\n",
    "    for i in range(data.shape[0]):\n",
    "        tweet=data.iloc[i,-1]\n",
    "        tweet=re.sub(r'http\\S+', '', tweet)\n",
    "        tweet=re.sub('[^a-zA-z]',\" \",tweet)\n",
    "        tweet=tweet.lower()\n",
    "        tweet=word_tokenize(tweet)\n",
    "#         tweet=[ps.stem(word) for word in tweet if word not in stopwords.words('english')]\n",
    "        tweet=[lemmatizer.lemmatize(word) for word in tweet if word not in stopwords.words('english')]\n",
    "        tweet=[word for word in tweet if word not in set(string.punctuation)]\n",
    "        tweet=\" \".join(tweet)\n",
    "        corpus.append(tweet)\n",
    "    return corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3' style=\"font-family: Futura\"><b style=\"color:green\">Creating data clean function:</b><br>\n",
    "    in this function we are going remove puctuationa,stopword and changing to lower case<br>\n",
    "    i have commented one line in function which is for porter stemmer, i commented it because it is decresing model accuracy\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_corpus_train=dataclean(x_train)\n",
    "x_corpus_test=dataclean(test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3' style=\"font-family: Futura; color:green\">Data Cleaned</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dic=defaultdict(int)\n",
    "for text in x_corpus_train:\n",
    "    text=text.split()\n",
    "    for word in text:\n",
    "        dic[word]=dic[word]+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size='3' style=\"font-family: Futura\">Sorting values through frequency of word</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('co', 4746),\n",
       " ('http', 4720),\n",
       " ('fire', 356),\n",
       " ('like', 350),\n",
       " ('u', 347),\n",
       " ('amp', 344),\n",
       " ('get', 255),\n",
       " ('new', 227),\n",
       " ('via', 220),\n",
       " ('news', 212),\n",
       " ('one', 207),\n",
       " ('people', 201),\n",
       " ('time', 181),\n",
       " ('year', 178),\n",
       " ('w', 177),\n",
       " ('video', 174),\n",
       " ('disaster', 162),\n",
       " ('emergency', 159),\n",
       " ('p', 156),\n",
       " ('body', 155),\n",
       " ('day', 151),\n",
       " ('r', 145),\n",
       " ('x', 145),\n",
       " ('home', 144),\n",
       " ('police', 143),\n",
       " ('building', 141),\n",
       " ('c', 141),\n",
       " ('would', 137),\n",
       " ('go', 137),\n",
       " ('b', 137),\n",
       " ('family', 132),\n",
       " ('life', 131),\n",
       " ('say', 131),\n",
       " ('still', 129),\n",
       " ('e', 128),\n",
       " ('storm', 128),\n",
       " ('n', 127),\n",
       " ('got', 125),\n",
       " ('v', 125),\n",
       " ('crash', 124),\n",
       " ('back', 122),\n",
       " ('california', 121),\n",
       " ('burning', 121),\n",
       " ('bomb', 121),\n",
       " ('look', 120),\n",
       " ('know', 120),\n",
       " ('suicide', 120),\n",
       " ('man', 117),\n",
       " ('death', 117),\n",
       " ('world', 117),\n",
       " ('car', 116),\n",
       " ('flood', 115),\n",
       " ('train', 115),\n",
       " ('see', 112),\n",
       " ('l', 111),\n",
       " ('pm', 111),\n",
       " ('rt', 110),\n",
       " ('attack', 110),\n",
       " ('first', 109),\n",
       " ('love', 107),\n",
       " ('k', 107),\n",
       " ('g', 105),\n",
       " ('h', 105),\n",
       " ('two', 104),\n",
       " ('make', 104),\n",
       " ('going', 104),\n",
       " ('nuclear', 104),\n",
       " ('today', 102),\n",
       " ('let', 102),\n",
       " ('war', 101),\n",
       " ('killed', 99),\n",
       " ('q', 98),\n",
       " ('dead', 98),\n",
       " ('accident', 98),\n",
       " ('youtube', 98),\n",
       " ('gt', 96),\n",
       " ('want', 95),\n",
       " ('hiroshima', 95),\n",
       " ('full', 94),\n",
       " ('need', 93),\n",
       " ('woman', 93),\n",
       " ('old', 93),\n",
       " ('take', 91),\n",
       " ('j', 90),\n",
       " ('way', 89),\n",
       " ('f', 89),\n",
       " ('good', 89),\n",
       " ('think', 89),\n",
       " ('weapon', 89),\n",
       " ('may', 88),\n",
       " ('z', 87),\n",
       " ('injury', 87),\n",
       " ('watch', 86),\n",
       " ('na', 85),\n",
       " ('bag', 85),\n",
       " ('many', 84),\n",
       " ('last', 83),\n",
       " ('could', 83),\n",
       " ('service', 83),\n",
       " ('wildfire', 81),\n",
       " ('collapse', 80),\n",
       " ('bombing', 79),\n",
       " ('work', 77),\n",
       " ('help', 77),\n",
       " ('plan', 76),\n",
       " ('best', 75),\n",
       " ('mass', 75),\n",
       " ('mh', 75),\n",
       " ('right', 74),\n",
       " ('thing', 74),\n",
       " ('hostage', 74),\n",
       " ('fatality', 74),\n",
       " ('please', 73),\n",
       " ('even', 73),\n",
       " ('come', 73),\n",
       " ('another', 72),\n",
       " ('army', 72),\n",
       " ('school', 71),\n",
       " ('really', 71),\n",
       " ('lol', 71),\n",
       " ('black', 69),\n",
       " ('city', 69),\n",
       " ('water', 69),\n",
       " ('kill', 68),\n",
       " ('fear', 68),\n",
       " ('forest', 67),\n",
       " ('photo', 67),\n",
       " ('fatal', 67),\n",
       " ('hot', 67),\n",
       " ('read', 66),\n",
       " ('state', 66),\n",
       " ('feel', 66),\n",
       " ('casualty', 66),\n",
       " ('god', 65),\n",
       " ('obama', 65),\n",
       " ('live', 64),\n",
       " ('much', 64),\n",
       " ('house', 64),\n",
       " ('northern', 64),\n",
       " ('reddit', 64),\n",
       " ('never', 63),\n",
       " ('great', 62),\n",
       " ('legionnaire', 62),\n",
       " ('bomber', 62),\n",
       " ('cause', 61),\n",
       " ('damage', 61),\n",
       " ('hit', 61),\n",
       " ('wave', 60),\n",
       " ('wreck', 60),\n",
       " ('latest', 60),\n",
       " ('japan', 60),\n",
       " ('area', 59),\n",
       " ('every', 59),\n",
       " ('th', 59),\n",
       " ('run', 59),\n",
       " ('report', 59),\n",
       " ('typhoon', 59),\n",
       " ('top', 58),\n",
       " ('stop', 58),\n",
       " ('im', 58),\n",
       " ('atomic', 58),\n",
       " ('flame', 58),\n",
       " ('everyone', 57),\n",
       " ('said', 57),\n",
       " ('content', 57),\n",
       " ('thunderstorm', 57),\n",
       " ('near', 56),\n",
       " ('getting', 56),\n",
       " ('shit', 56),\n",
       " ('ever', 56),\n",
       " ('change', 56),\n",
       " ('injured', 56),\n",
       " ('wind', 56),\n",
       " ('cross', 56),\n",
       " ('siren', 55),\n",
       " ('hope', 55),\n",
       " ('oil', 55),\n",
       " ('rain', 54),\n",
       " ('truck', 54),\n",
       " ('since', 54),\n",
       " ('girl', 54),\n",
       " ('show', 54),\n",
       " ('earthquake', 53),\n",
       " ('evacuation', 53),\n",
       " ('night', 53),\n",
       " ('boy', 53),\n",
       " ('movie', 53),\n",
       " ('warning', 53),\n",
       " ('fall', 53),\n",
       " ('coming', 52),\n",
       " ('set', 52),\n",
       " ('game', 52),\n",
       " ('found', 52),\n",
       " ('weather', 52),\n",
       " ('military', 52),\n",
       " ('next', 51),\n",
       " ('official', 51),\n",
       " ('without', 51),\n",
       " ('story', 51),\n",
       " ('as', 51),\n",
       " ('flooding', 50),\n",
       " ('end', 50),\n",
       " ('head', 50),\n",
       " ('st', 50),\n",
       " ('debris', 50),\n",
       " ('little', 50),\n",
       " ('well', 50),\n",
       " ('malaysia', 50),\n",
       " ('smoke', 49),\n",
       " ('update', 49),\n",
       " ('face', 49),\n",
       " ('call', 49),\n",
       " ('wild', 49),\n",
       " ('terrorist', 49),\n",
       " ('keep', 49),\n",
       " ('heat', 48),\n",
       " ('bus', 48),\n",
       " ('check', 48),\n",
       " ('food', 48),\n",
       " ('child', 48),\n",
       " ('post', 48),\n",
       " ('refugee', 48),\n",
       " ('wounded', 48),\n",
       " ('migrant', 48),\n",
       " ('gon', 47),\n",
       " ('road', 47),\n",
       " ('explosion', 47),\n",
       " ('guy', 47),\n",
       " ('job', 47),\n",
       " ('high', 47),\n",
       " ('sound', 47),\n",
       " ('confirmed', 47),\n",
       " ('severe', 47),\n",
       " ('week', 46),\n",
       " ('always', 46),\n",
       " ('fucking', 46),\n",
       " ('bad', 46),\n",
       " ('yr', 46),\n",
       " ('made', 46),\n",
       " ('lightning', 46),\n",
       " ('sinking', 46),\n",
       " ('bloody', 45),\n",
       " ('hour', 45),\n",
       " ('red', 45),\n",
       " ('fan', 45),\n",
       " ('natural', 45),\n",
       " ('devastated', 45),\n",
       " ('thunder', 45),\n",
       " ('summer', 44),\n",
       " ('someone', 44),\n",
       " ('also', 44),\n",
       " ('free', 44),\n",
       " ('murder', 44),\n",
       " ('blood', 44),\n",
       " ('liked', 44),\n",
       " ('spill', 44),\n",
       " ('loud', 44),\n",
       " ('shot', 43),\n",
       " ('tonight', 43),\n",
       " ('minute', 43),\n",
       " ('screaming', 43),\n",
       " ('air', 43),\n",
       " ('lot', 43),\n",
       " ('sign', 43),\n",
       " ('hail', 43),\n",
       " ('light', 43),\n",
       " ('missing', 43),\n",
       " ('hurricane', 43),\n",
       " ('evacuate', 43),\n",
       " ('failure', 43),\n",
       " ('china', 43),\n",
       " ('breaking', 42),\n",
       " ('kid', 42),\n",
       " ('eye', 42),\n",
       " ('ambulance', 42),\n",
       " ('ok', 42),\n",
       " ('survivor', 42),\n",
       " ('save', 42),\n",
       " ('terrorism', 42),\n",
       " ('big', 42),\n",
       " ('outbreak', 42),\n",
       " ('panic', 42),\n",
       " ('baby', 42),\n",
       " ('bridge', 42),\n",
       " ('riot', 42),\n",
       " ('hazard', 42),\n",
       " ('harm', 42),\n",
       " ('trapped', 42),\n",
       " ('collided', 42),\n",
       " ('collision', 42),\n",
       " ('rescue', 42),\n",
       " ('sinkhole', 42),\n",
       " ('island', 41),\n",
       " ('phone', 41),\n",
       " ('destroy', 41),\n",
       " ('whole', 41),\n",
       " ('survive', 41),\n",
       " ('business', 41),\n",
       " ('saudi', 41),\n",
       " ('released', 41),\n",
       " ('attacked', 41),\n",
       " ('explode', 41),\n",
       " ('derailment', 41),\n",
       " ('wreckage', 41),\n",
       " ('tornado', 40),\n",
       " ('around', 40),\n",
       " ('heart', 40),\n",
       " ('issue', 40),\n",
       " ('long', 40),\n",
       " ('part', 40),\n",
       " ('friend', 40),\n",
       " ('destroyed', 40),\n",
       " ('fuck', 40),\n",
       " ('battle', 40),\n",
       " ('ruin', 40),\n",
       " ('drought', 40),\n",
       " ('landslide', 40),\n",
       " ('rescued', 40),\n",
       " ('windstorm', 40),\n",
       " ('market', 39),\n",
       " ('burned', 39),\n",
       " ('trauma', 39),\n",
       " ('destruction', 39),\n",
       " ('start', 39),\n",
       " ('charged', 39),\n",
       " ('real', 39),\n",
       " ('land', 39),\n",
       " ('bombed', 39),\n",
       " ('rescuer', 39),\n",
       " ('crush', 39),\n",
       " ('hundred', 39),\n",
       " ('survived', 39),\n",
       " ('twister', 39),\n",
       " ('wrecked', 39),\n",
       " ('officer', 38),\n",
       " ('order', 38),\n",
       " ('county', 38),\n",
       " ('airplane', 38),\n",
       " ('self', 38),\n",
       " ('away', 38),\n",
       " ('white', 38),\n",
       " ('group', 38),\n",
       " ('put', 38),\n",
       " ('word', 38),\n",
       " ('displaced', 38),\n",
       " ('boat', 38),\n",
       " ('catastrophe', 38),\n",
       " ('wound', 38),\n",
       " ('deluge', 38),\n",
       " ('dust', 38),\n",
       " ('sunk', 38),\n",
       " ('suspect', 37),\n",
       " ('crashed', 37),\n",
       " ('thought', 37),\n",
       " ('august', 37),\n",
       " ('armageddon', 37),\n",
       " ('violent', 37),\n",
       " ('twitter', 37),\n",
       " ('pic', 37),\n",
       " ('half', 37),\n",
       " ('hazardous', 37),\n",
       " ('collapsed', 37),\n",
       " ('cliff', 37),\n",
       " ('curfew', 37),\n",
       " ('danger', 37),\n",
       " ('stock', 37),\n",
       " ('devastation', 37),\n",
       " ('famine', 37),\n",
       " ('investigator', 37),\n",
       " ('massacre', 37),\n",
       " ('mudslide', 37),\n",
       " ('quarantine', 37),\n",
       " ('structural', 37),\n",
       " ('sandstorm', 37),\n",
       " ('scream', 37),\n",
       " ('whirlwind', 37),\n",
       " ('second', 36),\n",
       " ('better', 36),\n",
       " ('least', 36),\n",
       " ('came', 36),\n",
       " ('plane', 36),\n",
       " ('iran', 36),\n",
       " ('national', 36),\n",
       " ('saw', 36),\n",
       " ('mosque', 36),\n",
       " ('power', 36),\n",
       " ('wan', 36),\n",
       " ('oh', 36),\n",
       " ('tragedy', 36),\n",
       " ('rioting', 36),\n",
       " ('traumatised', 36),\n",
       " ('chemical', 36),\n",
       " ('drowning', 36),\n",
       " ('engulfed', 36),\n",
       " ('screamed', 36),\n",
       " ('bang', 36),\n",
       " ('quarantined', 36),\n",
       " ('rd', 35),\n",
       " ('horrible', 35),\n",
       " ('past', 35),\n",
       " ('left', 35),\n",
       " ('heard', 35),\n",
       " ('fight', 35),\n",
       " ('zone', 35),\n",
       " ('apocalypse', 35),\n",
       " ('tomorrow', 35),\n",
       " ('song', 35),\n",
       " ('fedex', 35),\n",
       " ('bleeding', 35),\n",
       " ('effect', 35),\n",
       " ('blown', 35),\n",
       " ('anniversary', 35),\n",
       " ('derail', 35),\n",
       " ('derailed', 35),\n",
       " ('desolation', 35),\n",
       " ('detonate', 35),\n",
       " ('exploded', 35),\n",
       " ('hijacker', 35),\n",
       " ('inundated', 35),\n",
       " ('use', 34),\n",
       " ('meltdown', 34),\n",
       " ('book', 34),\n",
       " ('must', 34),\n",
       " ('went', 34),\n",
       " ('river', 34),\n",
       " ('blast', 34),\n",
       " ('blew', 34),\n",
       " ('drown', 34),\n",
       " ('ur', 34),\n",
       " ('murderer', 34),\n",
       " ('volcano', 34),\n",
       " ('catastrophic', 34),\n",
       " ('isi', 34),\n",
       " ('trouble', 34),\n",
       " ('electrocuted', 34),\n",
       " ('flattened', 34),\n",
       " ('lava', 34),\n",
       " ('pandemonium', 34),\n",
       " ('cool', 33),\n",
       " ('something', 33),\n",
       " ('thank', 33),\n",
       " ('reunion', 33),\n",
       " ('men', 33),\n",
       " ('government', 33),\n",
       " ('ebay', 33),\n",
       " ('soon', 33),\n",
       " ('shoulder', 33),\n",
       " ('stay', 33),\n",
       " ('person', 33),\n",
       " ('calgary', 33),\n",
       " ('bioterror', 33),\n",
       " ('lady', 33),\n",
       " ('bagging', 33),\n",
       " ('caused', 33),\n",
       " ('affected', 33),\n",
       " ('responder', 33),\n",
       " ('collide', 33),\n",
       " ('demolish', 33),\n",
       " ('evacuated', 33),\n",
       " ('panicking', 33),\n",
       " ('razed', 33),\n",
       " ('street', 32),\n",
       " ('south', 32),\n",
       " ('possible', 32),\n",
       " ('ship', 32),\n",
       " ('sure', 32),\n",
       " ('medium', 32),\n",
       " ('deal', 32),\n",
       " ('abc', 32),\n",
       " ('send', 32),\n",
       " ('demolition', 32),\n",
       " ('eyewitness', 32),\n",
       " ('hijacking', 32),\n",
       " ('reason', 31),\n",
       " ('place', 31),\n",
       " ('due', 31),\n",
       " ('three', 31),\n",
       " ('care', 31),\n",
       " ('traffic', 31),\n",
       " ('stand', 31),\n",
       " ('airport', 31),\n",
       " ('lt', 31),\n",
       " ('dog', 31),\n",
       " ('annihilated', 31),\n",
       " ('case', 31),\n",
       " ('arson', 31),\n",
       " ('american', 31),\n",
       " ('india', 31),\n",
       " ('longer', 31),\n",
       " ('security', 31),\n",
       " ('blazing', 31),\n",
       " ('pkk', 31),\n",
       " ('memory', 31),\n",
       " ('crushed', 31),\n",
       " ('km', 31),\n",
       " ('cyclone', 31),\n",
       " ('detonation', 31),\n",
       " ('tsunami', 31),\n",
       " ('obliterated', 31),\n",
       " ('detonated', 31),\n",
       " ('site', 30),\n",
       " ('thanks', 30),\n",
       " ('used', 30),\n",
       " ('tell', 30),\n",
       " ('support', 30),\n",
       " ('shooting', 30),\n",
       " ('play', 30),\n",
       " ('yet', 30),\n",
       " ('music', 30),\n",
       " ('beautiful', 30),\n",
       " ('lab', 30),\n",
       " ('nothing', 30),\n",
       " ('find', 30),\n",
       " ('mp', 30),\n",
       " ('rise', 30),\n",
       " ('bush', 30),\n",
       " ('demolished', 30),\n",
       " ('drowned', 30),\n",
       " ('prebreak', 30),\n",
       " ('obliterate', 30),\n",
       " ('obliteration', 30),\n",
       " ('ablaze', 29),\n",
       " ('inside', 29),\n",
       " ('mean', 29),\n",
       " ('america', 29),\n",
       " ('already', 29),\n",
       " ('making', 29),\n",
       " ('done', 29),\n",
       " ('believe', 29),\n",
       " ('nigga', 29),\n",
       " ('country', 29),\n",
       " ('horror', 29),\n",
       " ('fun', 29),\n",
       " ('team', 29),\n",
       " ('remember', 29),\n",
       " ('avalanche', 29),\n",
       " ('health', 29),\n",
       " ('line', 29),\n",
       " ('policy', 29),\n",
       " ('electrocute', 29),\n",
       " ('hellfire', 29),\n",
       " ('offensive', 29),\n",
       " ('rainstorm', 29),\n",
       " ('stretcher', 29),\n",
       " ('upheaval', 29),\n",
       " ('died', 28),\n",
       " ('far', 28),\n",
       " ('wait', 28),\n",
       " ('leave', 28),\n",
       " ('actually', 28),\n",
       " ('wake', 28),\n",
       " ('bc', 28),\n",
       " ('action', 28),\n",
       " ('peace', 28),\n",
       " ('move', 28),\n",
       " ('gun', 28),\n",
       " ('israeli', 28),\n",
       " ('bioterrorism', 28),\n",
       " ('crew', 28),\n",
       " ('turkey', 28),\n",
       " ('seismic', 28),\n",
       " ('hijack', 28),\n",
       " ('sue', 28),\n",
       " ('reactor', 28),\n",
       " ('snowstorm', 28),\n",
       " ('la', 27),\n",
       " ('north', 27),\n",
       " ('month', 27),\n",
       " ('vehicle', 27),\n",
       " ('win', 27),\n",
       " ('brown', 27),\n",
       " ('die', 27),\n",
       " ('victim', 27),\n",
       " ('ago', 27),\n",
       " ('helicopter', 27),\n",
       " ('bar', 27),\n",
       " ('trying', 27),\n",
       " ('feeling', 27),\n",
       " ('star', 27),\n",
       " ('yes', 27),\n",
       " ('computer', 27),\n",
       " ('blight', 27),\n",
       " ('nearby', 27),\n",
       " ('aug', 27),\n",
       " ('image', 27),\n",
       " ('deluged', 27),\n",
       " ('declares', 27),\n",
       " ('side', 26),\n",
       " ('west', 26),\n",
       " ('nowplaying', 26),\n",
       " ('center', 26),\n",
       " ('history', 26),\n",
       " ('anything', 26),\n",
       " ('yeah', 26),\n",
       " ('level', 26),\n",
       " ('low', 26),\n",
       " ('soudelor', 26),\n",
       " ('tree', 26),\n",
       " ('islam', 26),\n",
       " ('rubble', 26),\n",
       " ('swallowed', 26),\n",
       " ('lost', 25),\n",
       " ('flag', 25),\n",
       " ('outside', 25),\n",
       " ('almost', 25),\n",
       " ('aircraft', 25),\n",
       " ('pakistan', 25),\n",
       " ('hey', 25),\n",
       " ('hell', 25),\n",
       " ('maybe', 25),\n",
       " ('data', 25),\n",
       " ('point', 25),\n",
       " ('rule', 25),\n",
       " ('tweet', 25),\n",
       " ('watching', 25),\n",
       " ('handbag', 25),\n",
       " ('bigger', 25),\n",
       " ('desolate', 25),\n",
       " ('saipan', 25),\n",
       " ('utc', 25),\n",
       " ('hat', 25),\n",
       " ('conclusively', 25),\n",
       " ('happy', 24),\n",
       " ('secret', 24),\n",
       " ('mom', 24),\n",
       " ('moment', 24),\n",
       " ('anyone', 24),\n",
       " ('reuters', 24),\n",
       " ('share', 24),\n",
       " ('name', 24),\n",
       " ('hand', 24),\n",
       " ('christian', 24),\n",
       " ('pick', 24),\n",
       " ('tv', 24),\n",
       " ('control', 24),\n",
       " ('ca', 24),\n",
       " ('million', 24),\n",
       " ('muslim', 24),\n",
       " ('literally', 24),\n",
       " ('transport', 24),\n",
       " ('searching', 24),\n",
       " ('rock', 24),\n",
       " ('link', 24),\n",
       " ('money', 24),\n",
       " ('spot', 24),\n",
       " ('hear', 24),\n",
       " ('projected', 24),\n",
       " ('bestnaijamade', 24),\n",
       " ('fast', 23),\n",
       " ('thousand', 23),\n",
       " ('talk', 23),\n",
       " ('finally', 23),\n",
       " ('property', 23),\n",
       " ('might', 23),\n",
       " ('couple', 23),\n",
       " ('everything', 23),\n",
       " ('ball', 23),\n",
       " ('annihilation', 23),\n",
       " ('human', 23),\n",
       " ('amid', 23),\n",
       " ('town', 23),\n",
       " ('blaze', 23),\n",
       " ('lie', 23),\n",
       " ('damn', 23),\n",
       " ('listen', 23),\n",
       " ('hollywood', 23),\n",
       " ('pretty', 23),\n",
       " ('firefighter', 23),\n",
       " ('online', 23),\n",
       " ('cake', 23),\n",
       " ('open', 23),\n",
       " ('pay', 23),\n",
       " ('though', 23),\n",
       " ('morning', 23),\n",
       " ('probably', 23),\n",
       " ('village', 23),\n",
       " ('saved', 23),\n",
       " ('manslaughter', 23),\n",
       " ('trench', 23),\n",
       " ('hailstorm', 23),\n",
       " ('try', 22),\n",
       " ('sky', 22),\n",
       " ('drive', 22),\n",
       " ('wrong', 22),\n",
       " ('expert', 22),\n",
       " ('feared', 22),\n",
       " ('em', 22),\n",
       " ('hate', 22),\n",
       " ('sorry', 22),\n",
       " ('seen', 22),\n",
       " ('major', 22),\n",
       " ('class', 22),\n",
       " ('crisis', 22),\n",
       " ('blue', 22),\n",
       " ('leather', 22),\n",
       " ('caught', 22),\n",
       " ('okay', 22),\n",
       " ('youth', 22),\n",
       " ('space', 22),\n",
       " ('australia', 22),\n",
       " ('problem', 22),\n",
       " ('nearly', 22),\n",
       " ('wow', 22),\n",
       " ('coach', 22),\n",
       " ('mark', 22),\n",
       " ('giant', 22),\n",
       " ('alarm', 22),\n",
       " ('course', 22),\n",
       " ('chance', 22),\n",
       " ('uk', 22),\n",
       " ('knock', 22),\n",
       " ('sensor', 22),\n",
       " ('refugio', 22),\n",
       " ('costlier', 22),\n",
       " ('miner', 22),\n",
       " ('heavy', 21),\n",
       " ('flash', 21),\n",
       " ('others', 21),\n",
       " ('huge', 21),\n",
       " ('daily', 21),\n",
       " ('omg', 21),\n",
       " ('crazy', 21),\n",
       " ('usa', 21),\n",
       " ('film', 21),\n",
       " ('called', 21),\n",
       " ('east', 21),\n",
       " ('claim', 21),\n",
       " ('texas', 21),\n",
       " ('force', 21),\n",
       " ('worst', 21),\n",
       " ('fukushima', 21),\n",
       " ('nd', 21),\n",
       " ('seek', 21),\n",
       " ('turn', 21),\n",
       " ('idea', 21),\n",
       " ('strike', 21),\n",
       " ('russian', 21),\n",
       " ('gbbo', 21),\n",
       " ('bbc', 21),\n",
       " ('passenger', 21),\n",
       " ('banned', 21),\n",
       " ('nw', 21),\n",
       " ('picking', 21),\n",
       " ('closed', 20),\n",
       " ('across', 20),\n",
       " ('haha', 20),\n",
       " ('lord', 20),\n",
       " ('chicago', 20),\n",
       " ('hard', 20),\n",
       " ('aftershock', 20),\n",
       " ('pilot', 20),\n",
       " ('cop', 20),\n",
       " ('number', 20),\n",
       " ('poor', 20),\n",
       " ('radio', 20),\n",
       " ('toddler', 20),\n",
       " ('united', 20),\n",
       " ('truth', 20),\n",
       " ('burn', 20),\n",
       " ('militant', 20),\n",
       " ('view', 20),\n",
       " ('favorite', 20),\n",
       " ('anthrax', 20),\n",
       " ('mishap', 20),\n",
       " ('running', 20),\n",
       " ('looking', 20),\n",
       " ('dont', 20),\n",
       " ('gem', 20),\n",
       " ('follow', 20),\n",
       " ('entire', 20),\n",
       " ('drake', 20),\n",
       " ('meek', 20),\n",
       " ('camp', 20),\n",
       " ('mph', 20),\n",
       " ('become', 20),\n",
       " ('company', 20),\n",
       " ('angry', 20),\n",
       " ('cnn', 20),\n",
       " ('ignition', 20),\n",
       " ('mayhem', 20),\n",
       " ('myanmar', 19),\n",
       " ('wanted', 19),\n",
       " ('alone', 19),\n",
       " ('arsonist', 19),\n",
       " ('climate', 19),\n",
       " ('else', 19),\n",
       " ('happened', 19),\n",
       " ('member', 19),\n",
       " ('ap', 19),\n",
       " ('driver', 19),\n",
       " ('horse', 19),\n",
       " ('soul', 19),\n",
       " ('mountain', 19),\n",
       " ('totally', 19),\n",
       " ('give', 19),\n",
       " ('russia', 19),\n",
       " ('lead', 19),\n",
       " ('hero', 19),\n",
       " ('date', 19),\n",
       " ('learn', 19),\n",
       " ('beach', 19),\n",
       " ('act', 19),\n",
       " ('temple', 19),\n",
       " ('mount', 19),\n",
       " ('sea', 19),\n",
       " ('taken', 19),\n",
       " ('playing', 19),\n",
       " ('public', 19),\n",
       " ('mad', 19),\n",
       " ('party', 19),\n",
       " ('foot', 19),\n",
       " ('pain', 19),\n",
       " ('art', 19),\n",
       " ('blizzard', 19),\n",
       " ('break', 19),\n",
       " ('large', 19),\n",
       " ('appears', 19),\n",
       " ('thursday', 19),\n",
       " ('centre', 19),\n",
       " ('issued', 19),\n",
       " ('emmerdale', 19),\n",
       " ('flight', 19),\n",
       " ('declaration', 19),\n",
       " ('disea', 19),\n",
       " ('spring', 18),\n",
       " ('cry', 18),\n",
       " ('front', 18),\n",
       " ('student', 18),\n",
       " ('risk', 18),\n",
       " ('scene', 18),\n",
       " ('dy', 18),\n",
       " ('dr', 18),\n",
       " ('comment', 18),\n",
       " ('ice', 18),\n",
       " ('global', 18),\n",
       " ('begin', 18),\n",
       " ('trust', 18),\n",
       " ('israel', 18),\n",
       " ('ready', 18),\n",
       " ('park', 18),\n",
       " ('disease', 18),\n",
       " ('till', 18),\n",
       " ('track', 18),\n",
       " ('green', 18),\n",
       " ('civilian', 18),\n",
       " ('king', 18),\n",
       " ('piece', 18),\n",
       " ('cover', 18),\n",
       " ('driving', 18),\n",
       " ('pc', 18),\n",
       " ('young', 18),\n",
       " ('miss', 18),\n",
       " ('germ', 18),\n",
       " ('ash', 18),\n",
       " ('dude', 18),\n",
       " ('info', 18),\n",
       " ('release', 18),\n",
       " ('room', 18),\n",
       " ('middle', 18),\n",
       " ('nagasaki', 18),\n",
       " ('downtown', 18),\n",
       " ('insurance', 18),\n",
       " ('british', 18),\n",
       " ('instead', 18),\n",
       " ('wonder', 18),\n",
       " ('quiz', 18),\n",
       " ('virgin', 18),\n",
       " ('chile', 18),\n",
       " ('london', 17),\n",
       " ('bring', 17),\n",
       " ('season', 17),\n",
       " ('taking', 17),\n",
       " ('reported', 17),\n",
       " ('turned', 17),\n",
       " ('behind', 17),\n",
       " ('france', 17),\n",
       " ('four', 17),\n",
       " ('wednesday', 17),\n",
       " ('early', 17),\n",
       " ('following', 17),\n",
       " ('scared', 17),\n",
       " ('beat', 17),\n",
       " ('escape', 17),\n",
       " ('hiring', 17),\n",
       " ('true', 17),\n",
       " ('theater', 17),\n",
       " ('gave', 17),\n",
       " ('gop', 17),\n",
       " ('answer', 17),\n",
       " ('added', 17),\n",
       " ('threat', 17),\n",
       " ('wall', 17),\n",
       " ('sad', 17),\n",
       " ('tote', 17),\n",
       " ('libya', 17),\n",
       " ('outrage', 17),\n",
       " ('brother', 17),\n",
       " ('ppl', 17),\n",
       " ('sex', 17),\n",
       " ('animal', 17),\n",
       " ('cost', 17),\n",
       " ('landing', 17),\n",
       " ('cat', 17),\n",
       " ('download', 17),\n",
       " ('york', 17),\n",
       " ('patience', 17),\n",
       " ('former', 17),\n",
       " ('madhya', 17),\n",
       " ('pradesh', 17),\n",
       " ('nigerian', 17),\n",
       " ('led', 17),\n",
       " ('lamp', 17),\n",
       " ('bayelsa', 17),\n",
       " ('funtenna', 17),\n",
       " ('ancient', 17),\n",
       " ('subreddits', 17),\n",
       " ('galactic', 17),\n",
       " ('lake', 16),\n",
       " ('colorado', 16),\n",
       " ('awesome', 16),\n",
       " ('ave', 16),\n",
       " ('upon', 16),\n",
       " ('michael', 16),\n",
       " ('teen', 16),\n",
       " ('owner', 16),\n",
       " ('dance', 16),\n",
       " ('seeing', 16),\n",
       " ('thinking', 16),\n",
       " ('mode', 16),\n",
       " ('close', 16),\n",
       " ('pakistani', 16),\n",
       " ('career', 16),\n",
       " ('fact', 16),\n",
       " ('potus', 16),\n",
       " ('question', 16),\n",
       " ('dad', 16),\n",
       " ('bed', 16),\n",
       " ('series', 16),\n",
       " ('department', 16),\n",
       " ('earth', 16),\n",
       " ('working', 16),\n",
       " ('sport', 16),\n",
       " ('palestinian', 16),\n",
       " ('lmao', 16),\n",
       " ('shift', 16),\n",
       " ('pamela', 16),\n",
       " ('gas', 16),\n",
       " ('cut', 16),\n",
       " ('ft', 16),\n",
       " ('ebola', 16),\n",
       " ('event', 16),\n",
       " ('coast', 16),\n",
       " ('silver', 16),\n",
       " ('enough', 16),\n",
       " ('bitch', 16),\n",
       " ('told', 16),\n",
       " ('falling', 16),\n",
       " ('buy', 16),\n",
       " ('biggest', 16),\n",
       " ('fashion', 16),\n",
       " ('gunman', 16),\n",
       " ('pray', 16),\n",
       " ('holding', 16),\n",
       " ('likely', 16),\n",
       " ('xd', 16),\n",
       " ('desire', 16),\n",
       " ('insurer', 16),\n",
       " ('disney', 16),\n",
       " ('sick', 16),\n",
       " ('parole', 16),\n",
       " ('unconfirmed', 16),\n",
       " ('neighbour', 16),\n",
       " ('rly', 16),\n",
       " ('expected', 15),\n",
       " ('direction', 15),\n",
       " ('aba', 15),\n",
       " ('office', 15),\n",
       " ('el', 15),\n",
       " ('mile', 15),\n",
       " ('guess', 15),\n",
       " ('tried', 15),\n",
       " ('bb', 15),\n",
       " ('id', 15),\n",
       " ('bit', 15),\n",
       " ('petition', 15),\n",
       " ('walk', 15),\n",
       " ('safety', 15),\n",
       " ('match', 15),\n",
       " ('le', 15),\n",
       " ('started', 15),\n",
       " ('door', 15),\n",
       " ('indian', 15),\n",
       " ('japanese', 15),\n",
       " ('arrested', 15),\n",
       " ('capture', 15),\n",
       " ('drink', 15),\n",
       " ('court', 15),\n",
       " ('terror', 15),\n",
       " ('user', 15),\n",
       " ('worry', 15),\n",
       " ...]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data=sorted(dic.items(), key=lambda x:x[1],reverse=True)\n",
    "sorted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-family: Futura; color:green \"><b>4. Feature Scalling</b></h2><br><a id='4'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv=TfidfVectorizer(max_features=8000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_vector=cv.fit_transform(x_corpus_train).toarray()\n",
    "x_test_vector=cv.transform(x_corpus_test).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-family: Futura; color:green \"><b>5. Modeling</b></h2><br><a id='5'></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: Futura; color:blue \"><b>1. Naive Bayes</b></h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8715355313279916\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 0, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model=MultinomialNB()\n",
    "model.fit(x_train_vector,y_train)\n",
    "print(model.score(x_train_vector,y_train))\n",
    "y_pred=model.predict(x_test_vector)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: Futura; color:blue \"><b>2. Randomforest</b></h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6327334822014974\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "rfc=RandomForestClassifier(random_state=4,n_estimators=500,warm_start=True,max_depth=6,min_samples_leaf=2,max_features='auto',min_samples_split=3)\n",
    "rfc.fit(x_train_vector,y_train)\n",
    "print(rfc.score(x_train_vector,y_train))\n",
    "y_pred=rfc.predict(x_test_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: Futura; color:blue \"><b>3. XGBoost</b></h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8615526073821096\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBClassifier\n",
    "xgb=XGBClassifier()\n",
    "xgb.fit(x_train_vector,y_train,early_stopping_rounds=5, \n",
    "             eval_set=[(x_train_vector,y_train)], \n",
    "             verbose=False)\n",
    "print(xgb.score(x_train_vector,y_train))\n",
    "y_pred=xgb.predict(x_test_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: Futura; color:blue \"><b>4. Logistic Regression</b></h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8771837646131617\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "reg=LogisticRegression()\n",
    "reg.fit(x_train_vector,y_train)\n",
    "print(reg.score(x_train_vector,y_train))\n",
    "y_pred=reg.predict(x_test_vector)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: Futura; color:blue \"><b>5. PassiveAggressiveClassifier</b></h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9869959280178642\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1, 1, 1, ..., 1, 1, 1], dtype=int64)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import PassiveAggressiveClassifier\n",
    "passive=PassiveAggressiveClassifier()\n",
    "passive.fit(x_train_vector,y_train)\n",
    "print(passive.score(x_train_vector,y_train))\n",
    "y_pred=passive.predict(x_test_vector)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3 style=\"font-family: Futura; color:blue \"><b>6. KNN</b></h3><br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-28-42db76f40f2e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclassifier\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNeighborsClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_neighbors\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_vector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train_vector\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mclassifier\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test_vector\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36mscore\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    367\u001b[0m         \"\"\"\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 369\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    370\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_classification.py\u001b[0m in \u001b[0;36mpredict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    171\u001b[0m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    172\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 173\u001b[1;33m         \u001b[0mneigh_dist\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneigh_ind\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkneighbors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    174\u001b[0m         \u001b[0mclasses_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    175\u001b[0m         \u001b[0m_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_y\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36mkneighbors\u001b[1;34m(self, X, n_neighbors, return_distance)\u001b[0m\n\u001b[0;32m    661\u001b[0m                 delayed_query(\n\u001b[0;32m    662\u001b[0m                     self._tree, X[s], n_neighbors, return_distance)\n\u001b[1;32m--> 663\u001b[1;33m                 \u001b[1;32mfor\u001b[0m \u001b[0ms\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mgen_even_slices\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    664\u001b[0m             )\n\u001b[0;32m    665\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1002\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1003\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1004\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1005\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1006\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    833\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    834\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 835\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    836\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    837\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    752\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    753\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 754\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    755\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    756\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    207\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    208\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 209\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    210\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    211\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    588\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    589\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 590\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    591\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    592\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    254\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    255\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 256\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    257\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    258\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\sklearn\\neighbors\\_base.py\u001b[0m in \u001b[0;36m_tree_query_parallel_helper\u001b[1;34m(tree, *args, **kwargs)\u001b[0m\n\u001b[0;32m    488\u001b[0m     \u001b[0munder\u001b[0m \u001b[0mPyPy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m     \"\"\"\n\u001b[1;32m--> 490\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mquery\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    491\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    492\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "classifier = KNeighborsClassifier(n_neighbors = 2)\n",
    "classifier.fit(x_train_vector,y_train)\n",
    "print(classifier.score(x_train_vector,y_train))\n",
    "y_pred=classifier.predict(x_test_vector)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 style=\"font-family: Futura; color:green \"><b>6. Submission</b></h2><br><a id='6'></a>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission=pd.read_csv('sample_submission.csv')\n",
    "submission['target']=y_pred\n",
    "submission.to_csv('submission.csv',index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
